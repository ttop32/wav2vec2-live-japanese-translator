{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58faa035-2a8f-41b0-817e-d568a069ada6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "common_voice\n",
    "https://huggingface.co/datasets/common_voice\n",
    "\n",
    "JSUT (Japanese speech corpus of Saruwatari-lab., University of Tokyo)\n",
    "https://sites.google.com/site/shinnosuketakamichi/publication/jsut\n",
    "\n",
    "CSS10: A Collection of Single Speaker Speech Datasets for 10 Languages\n",
    "https://github.com/Kyubyong/css10\n",
    "\n",
    "\n",
    "TEDxJP-10K ASR Evaluation Dataset\n",
    "https://github.com/laboroai/TEDxJP-10K\n",
    "\n",
    "JVS (Japanese versatile speech) corpus\n",
    "https://sites.google.com/site/shinnosuketakamichi/research-topics/jvs_corpus\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c645aef0-cf27-4551-a977-b7c4a87c4a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download common voice\n",
    "from datasets import load_dataset\n",
    "common_voice_train = load_dataset(\"common_voice\", \"ja\", split=\"train+validation\")\n",
    "common_voice_test = load_dataset(\"common_voice\", \"ja\", split=\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee68fbaf-1aeb-44ba-be0b-41262899663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download JSUT (Japanese speech corpus of Saruwatari-lab., University of Tokyo)\n",
    "!wget http://ss-takashi.sakura.ne.jp/corpus/jsut_ver1.1.zip\n",
    "!unzip \"./jsut_ver1.1.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3598de39-305f-4cc8-914e-c79923c987eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSS10: A Collection of Single Speaker Speech Datasets for 10 Languages\n",
    "# get KAGGLE_KEY from https://www.kaggle.com/<username>/account\n",
    "\n",
    "import os\n",
    "os.environ['KAGGLE_USERNAME'] = \"\"\n",
    "os.environ['KAGGLE_KEY'] = \"\"\n",
    "!pip install --user kaggle\n",
    "!kaggle datasets download -d bryanpark/japanese-single-speaker-speech-dataset\n",
    "!unzip japanese-single-speaker-speech-dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f859253-af19-4c3a-83c0-89429b299bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download TEDxJP-10K ASR Evaluation Dataset git\n",
    "!pip install youtube-dl\n",
    "!git clone https://github.com/laboroai/TEDxJP-10K.git \n",
    "!sudo apt install sox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04ac385-e59d-4a7f-bfac-3859b69226a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download TEDxJP-10K ASR Evaluation Dataset youtube\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import youtube_dl\n",
    "import time\n",
    "\n",
    "lines=[]\n",
    "with open(\"TEDxJP-10K/data/tedx-jp_urls.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "command=\"\"\"youtube-dl \\\n",
    "\t--extract-audio \\\n",
    "\t--audio-format wav \\\n",
    "\t--write-sub \\\n",
    "\t--sub-format vtt \\\n",
    "\t--sub-lang ja \\\n",
    "\t--output \"TEDxJP-10K/temp/raw/%(id)s.%(ext)s\" \\\n",
    "    \"\"\"\n",
    "path=\"TEDxJP-10K/temp/raw/\"\n",
    "\n",
    "for url in tqdm(lines):\n",
    "    urlId=url[32:-1]\n",
    "    if os.path.exists(path+urlId+\".ja.vtt\") and os.path.exists(path+urlId+\".wav\"):\n",
    "        continue\n",
    "    print(urlId)\n",
    "    stream = os.popen(command+lines[0])\n",
    "    output = stream.read()\n",
    "    time.sleep(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4473fcd5-3d8d-48a2-8185-86b90511aca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process TEDxJP-10K ASR Evaluation Dataset caption\n",
    "!cd TEDxJP-10K&&python compose_tedxjp10k.py temp/raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78cc63c-f369-4841-b46f-a52f11ab917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slice TEDxJP-10K audio based on time given\n",
    "import torchaudio\n",
    "import os \n",
    "datasets_TEDxJP = load_dataset('csv', data_files=\"TEDxJP-10K/TEDxJP-10K_v1.1/text\",delimiter=\" \",column_names=[\"name\",\"sentence\"])[\"train\"]\n",
    "saveDir=\"./TEDxJP/\"\n",
    "csvPath=\"TEDxJP.txt\"\n",
    "\n",
    "if not os.path.exists(saveDir):\n",
    "    os.makedirs(saveDir)\n",
    "\n",
    "if os.path.exists(csvPath):\n",
    "    os.remove(csvPath)\n",
    "    \n",
    "\n",
    "def splitTime(batch):\n",
    "    #save split audio\n",
    "    splitResult=batch[\"name\"].split(\"-\")\n",
    "    batch[\"path\"]=\"TEDxJP-10K/TEDxJP-10K_v1.1/wav/\"+\"-\".join(splitResult[:-2])+\".16k.wav\"\n",
    "    batch[\"timeStart\"]=int(int(splitResult[-2])/100*16000)\n",
    "    batch[\"timeEnd\"]=int((int(splitResult[-1])-int(splitResult[-2]))/100*16000)\n",
    "    savePath=saveDir+batch[\"name\"]+\".wav\"\n",
    "    waveform, sample_rate = torchaudio.load(batch[\"path\"], frame_offset=batch[\"timeStart\"], num_frames=batch[\"timeEnd\"])\n",
    "    torchaudio.save(savePath, waveform, sample_rate)\n",
    "\n",
    "    #save csv\n",
    "    with open(csvPath, \"a\") as file:\n",
    "        file.write(savePath+\"|\"+batch[\"sentence\"]+\"\\n\")\n",
    "    return batch\n",
    "\n",
    "datasets_TEDxJP=datasets_TEDxJP.map(splitTime)\n",
    "print(datasets_TEDxJP)\n",
    "print(datasets_TEDxJP[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "043a7fb2-919a-4d89-a7a6-ecf4b34b622c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=19oAw8wWn3Y7z6CKChRdAyGOB9yupL_Xt\n",
      "To: /home/user/code/jupyter/voice/jvs_ver1.zip\n",
      "100%|██████████████████████████████████████| 3.54G/3.54G [03:18<00:00, 17.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown\n",
    "\n",
    "# https://sites.google.com/site/shinnosuketakamichi/research-topics/jvs_corpus\n",
    "# jvs\n",
    "!gdown https://drive.google.com/uc?id=19oAw8wWn3Y7z6CKChRdAyGOB9yupL_Xt\n",
    "!unzip jvs_ver1.zip\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8890c3cb-0776-4e95-8492-92e242f6cb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://sites.google.com/site/shinnosuketakamichi/research-topics/jsss_corpus\n",
    "# !gdown https://drive.google.com/uc?id=1NyiZCXkYTdYBNtD1B-IMAYCVa-0SQsKX\n",
    "# !unzip jsss_ver1.zip\n",
    "\n",
    "\n",
    "# import torchaudio\n",
    "# from datasets import load_dataset\n",
    "# from pathlib import Path  \n",
    "# import os\n",
    "# import glob\n",
    "\n",
    "# savePath=\"./preprocess_jsss_ver1/\"\n",
    "# prepreocessCsvPath=\"preprocess_jsss_ver1.txt\"\n",
    "# if not os.path.exists(savePath):\n",
    "#     os.makedirs(savePath)\n",
    "\n",
    "# if os.path.exists(prepreocessCsvPath):\n",
    "#     os.remove(prepreocessCsvPath)\n",
    "\n",
    "    \n",
    "# transcript_utf8_list=glob.glob(\"jsss_ver1/long-form/*/transcript_utf8/*.txt\")\n",
    "# transcript_utf8_list+=glob.glob(\"jsss_ver1/summarization/transcript_utf8/*.txt\")\n",
    "\n",
    "\n",
    "# for csvPath in transcript_utf8_list:\n",
    "#     datasets = load_dataset('csv', data_files=csvPath,delimiter=\"\\t\",column_names=[\"timeStart\",\"timeEnd\",\"sentence\"])[\"train\"]    \n",
    "    \n",
    "#     fileName=Path(csvPath).stem\n",
    "#     wavPath=os.path.abspath(os.path.join(csvPath, '../../wav24kHz16bit/')+fileName+\".wav\")\n",
    "    \n",
    "    \n",
    "#     def splitTime(batch):\n",
    "#         #save split audio\n",
    "#         waveform, sample_rate = torchaudio.load(wavPath)\n",
    "#         frameStart=int(float(batch[\"timeStart\"])*sample_rate)\n",
    "#         frameDuration=int((float(batch[\"timeEnd\"])-float(batch[\"timeStart\"]))*sample_rate)\n",
    "#         savePathWav=savePath+fileName+\"_\"+str(frameStart)+\".wav\"\n",
    "#         waveform, sample_rate = torchaudio.load(wavPath, frame_offset=frameStart, num_frames=frameDuration)\n",
    "#         torchaudio.save(savePathWav, waveform, sample_rate)\n",
    "        \n",
    "#         #save csv\n",
    "#         with open(prepreocessCsvPath, \"a\") as file:\n",
    "#             file.write(savePathWav+\"\\t\"+batch[\"sentence\"]+\"\\n\")\n",
    "#         return batch\n",
    "\n",
    "#     datasets=datasets.map(splitTime)\n",
    "    \n",
    "\n",
    "# #csvPath=\"preprocess_jsss_ver1.txt\"\n",
    "# #datasets = load_dataset('csv', data_files=csvPath,delimiter=\"\\t\",column_names=[\"path\",\"sentence\"])[\"train\"]    \n",
    "\n",
    "\n",
    "# import os\n",
    "# from datasets import load_dataset\n",
    "# transcript_utf8_list=glob.glob(\"jsss_ver1/short-form/*/transcript_utf8.txt\")\n",
    "# transcript_utf8_list+=[\"jsss_ver1/simplification/transcript_utf8.txt\"]\n",
    "# transcript_utf8_list\n",
    "\n",
    "# datasets_jsss_list=[]\n",
    "# for csvPath in transcript_utf8_list:\n",
    "#     datasets = load_dataset('csv', data_files=csvPath,delimiter=\":\",column_names=[\"path\",\"sentence\"])[\"train\"]\n",
    "#     datasets = datasets.map(lambda batch: {'path': os.path.dirname(csvPath)+\"/wav24kHz16bit/\"+batch['path']+\".wav\"})\n",
    "#     datasets_jsss_list+=[datasets]\n",
    "# datasets_jsss_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
